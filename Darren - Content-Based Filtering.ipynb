{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Sample 5000.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10001 entries, 0 to 10000\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   event_time     10001 non-null  object \n",
      " 1   event_type     10001 non-null  object \n",
      " 2   product_id     10001 non-null  object \n",
      " 3   category_id    10001 non-null  int64  \n",
      " 4   category_code  6623 non-null   object \n",
      " 5   category1      6623 non-null   object \n",
      " 6   category2      6623 non-null   object \n",
      " 7   category3      2881 non-null   object \n",
      " 8   category4      2 non-null      object \n",
      " 9   brand          8595 non-null   object \n",
      " 10  price          10001 non-null  float64\n",
      " 11  user_id        10001 non-null  int64  \n",
      " 12  user_session   10001 non-null  object \n",
      " 13  interaction    10001 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(10)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['category1', 'category2', 'category3', 'category4'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Null Values\n",
    "- For brands that have null values, we're gonna replace with 'unknown' brand.\n",
    "- For category_code with null values, we're going to remove them because it would be useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          samsung\n",
       "1          samsung\n",
       "2             sony\n",
       "3            intel\n",
       "4          samsung\n",
       "           ...    \n",
       "9996           msi\n",
       "9997           msi\n",
       "9998     garanterm\n",
       "9999       samsung\n",
       "10000      samsung\n",
       "Name: brand, Length: 10001, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category_code'] = df['category_code'].fillna(value=\"empty\")\n",
    "df['category_code'].astype(str)\n",
    "\n",
    "df['brand'] = df['brand'].fillna(value=\"unknown\")\n",
    "df['brand'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_count = dict(df.user_id.value_counts())\n",
    "\n",
    "for row in df.iterrows():\n",
    "    \n",
    "    # Retrieving value\n",
    "    category_code_col = row[1]['category_code']\n",
    "    user_id_col = row[1]['user_id']\n",
    "    # Apply logic\n",
    "        ## We set {user-id: count_it_appears}\n",
    "        ## If count_it_appear == 1 and (category_code_col = nan), then we remove them\n",
    "        \n",
    "    count = users_count[user_id_col]\n",
    "    if count == 1 and category_code_col == 'empty':\n",
    "        df = df.drop(df[df.user_id == user_id_col].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values check:  \n",
      " event_time       0\n",
      "event_type       0\n",
      "product_id       0\n",
      "category_id      0\n",
      "category_code    0\n",
      "brand            0\n",
      "price            0\n",
      "user_id          0\n",
      "user_session     0\n",
      "interaction      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Null Values check: \", \"\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_score'] = df['event_type'].map({'view':1, 'cart':10, 'purchase':50})\n",
    "df['user_purchase'] = df['event_type'].apply(lambda x: 1 if x == 'purchase' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "      <th>interaction</th>\n",
       "      <th>user_score</th>\n",
       "      <th>user_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01 08:47:35 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1001588</td>\n",
       "      <td>2053013555631879936</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>samsung</td>\n",
       "      <td>460.50</td>\n",
       "      <td>244951053</td>\n",
       "      <td>91769fdf-461b-4e43-9c73-88a07481b75c</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-01 08:48:28 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1003535</td>\n",
       "      <td>2053013555631879936</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>samsung</td>\n",
       "      <td>460.50</td>\n",
       "      <td>244951053</td>\n",
       "      <td>91769fdf-461b-4e43-9c73-88a07481b75c</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-01 16:48:28 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>6400036</td>\n",
       "      <td>2053013554121929984</td>\n",
       "      <td>computers.components.cpu</td>\n",
       "      <td>intel</td>\n",
       "      <td>338.23</td>\n",
       "      <td>295655799</td>\n",
       "      <td>eb8f2cea-4c5b-4e00-880f-3bcfa28549ff</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-01 17:07:37 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1004870</td>\n",
       "      <td>2053013555631879936</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>samsung</td>\n",
       "      <td>286.84</td>\n",
       "      <td>306087674</td>\n",
       "      <td>a15f469a-968f-4c8c-8317-6dffed3f5523</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-10-01 17:15:42 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>44100021</td>\n",
       "      <td>2100065069302799872</td>\n",
       "      <td>empty</td>\n",
       "      <td>smoby</td>\n",
       "      <td>655.03</td>\n",
       "      <td>306087674</td>\n",
       "      <td>0c032f47-6050-4609-b07a-bf82d4b7c515</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type product_id          category_id  \\\n",
       "0  2019-10-01 08:47:35 UTC       view    1001588  2053013555631879936   \n",
       "1  2019-10-01 08:48:28 UTC       view    1003535  2053013555631879936   \n",
       "3  2019-10-01 16:48:28 UTC       view    6400036  2053013554121929984   \n",
       "4  2019-10-01 17:07:37 UTC       view    1004870  2053013555631879936   \n",
       "5  2019-10-01 17:15:42 UTC       view   44100021  2100065069302799872   \n",
       "\n",
       "              category_code    brand   price    user_id  \\\n",
       "0    electronics.smartphone  samsung  460.50  244951053   \n",
       "1    electronics.smartphone  samsung  460.50  244951053   \n",
       "3  computers.components.cpu    intel  338.23  295655799   \n",
       "4    electronics.smartphone  samsung  286.84  306087674   \n",
       "5                     empty    smoby  655.03  306087674   \n",
       "\n",
       "                           user_session  interaction  user_score  \\\n",
       "0  91769fdf-461b-4e43-9c73-88a07481b75c            1           1   \n",
       "1  91769fdf-461b-4e43-9c73-88a07481b75c            1           1   \n",
       "3  eb8f2cea-4c5b-4e00-880f-3bcfa28549ff            1           1   \n",
       "4  a15f469a-968f-4c8c-8317-6dffed3f5523            1           1   \n",
       "5  0c032f47-6050-4609-b07a-bf82d4b7c515            1           1   \n",
       "\n",
       "   user_purchase  \n",
       "0              0  \n",
       "1              0  \n",
       "3              0  \n",
       "4              0  \n",
       "5              0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['price_category'] = 1\n",
    "# for category_code in df['category_code'].unique():\n",
    "#     df.loc[df['category_code']==category_code,'price_category'] = pd.qcut(x=df['price'][df['category_code']==category_code],q=5, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category_code in df['category_code'].unique():\n",
    "    df['price_category'] = pd.qcut(df['price'],  \n",
    "                            q=[0, .2, .4, .6, .8, 1],\n",
    "                              labels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "group = df.groupby(['user_id', 'product_id'])['user_score', 'user_purchase'].sum().reset_index()\n",
    "group['user_purchase'] = group['user_purchase'].apply(lambda x: 1 if x>1 else x)\n",
    "group['user_score'] = group['user_score'].apply(lambda x: 100 if x>100 else x)\n",
    "\n",
    "# apply MinMaxScaler to the user scores to obtain an interaction score with a value between 0 and 1\n",
    "# >=0.5: a very high probability that a purchase has occurred\n",
    "# <0.5: no purchase occurs below the threshold of 0.5\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "std = MinMaxScaler(feature_range=(0.025, 1))\n",
    "std.fit(group['user_score'].values.reshape(-1,1))\n",
    "group['interaction_score'] = std.transform(group['user_score'].values.reshape(-1,1))\n",
    "\n",
    "group = group.merge(df[['product_id','category_code','brand','price','price_category']].drop_duplicates('product_id'),on=['product_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = group.drop('interaction_score', axis =1)\n",
    "X = inputs\n",
    "y = group['interaction_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(4803, 8)}\n",
      "(4803,)\n",
      "{(600, 8)}\n",
      "(600,)\n",
      "(601, 8)\n",
      "(601,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "\n",
    "# Now since we want the valid and test size to be equal (10% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "test_size = 0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "\n",
    "print({X_train.shape}), print(y_train.shape)\n",
    "print({X_valid.shape}), print(y_valid.shape)\n",
    "print(X_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matrix = pd.pivot_table(X_train,values='user_score',index='user_id',columns='product_id')\n",
    "X_train_matrix = X_train_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering by item category, price category and brand\n",
    "\n",
    "product_cat = X_train[['product_id','price_category','category_code','brand']].drop_duplicates('product_id')\n",
    "product_cat['product_id'] = product_cat['product_id'].astype(str)\n",
    "product_cat.sort_values(by='product_id', ascending=True, inplace=True)\n",
    "product_cat = product_cat.sort_values(by='product_id')\n",
    "\n",
    "# Reciprocal of 2 is 0.5, cos 1/2. \n",
    "price_cat_matrix = np.reciprocal(euclidean_distances(np.array(product_cat['price_category']).reshape(-1,1))+1)\n",
    "euclidean_matrix = pd.DataFrame(price_cat_matrix,columns=product_cat['product_id'],index=product_cat['product_id'])\n",
    "\n",
    "# TfidfVectorizer() converts texts to word freq counts... \n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "doc_term = tfidf_vectorizer.fit_transform(list(product_cat['category_code']))\n",
    "dt_matrix = pd.DataFrame(doc_term.toarray().round(3), index=[i for i in product_cat['product_id']], columns=tfidf_vectorizer.get_feature_names())\n",
    "cos_similar_matrix = pd.DataFrame(cosine_similarity(dt_matrix.values),columns=product_cat['product_id'],index=product_cat['product_id'])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "doc_term = tfidf_vectorizer.fit_transform(list(product_cat['brand']))\n",
    "dt_matrix1 = pd.DataFrame(doc_term.toarray().round(3), index=[i for i in product_cat['product_id']], columns=tfidf_vectorizer.get_feature_names())\n",
    "dt_matrix1 = dt_matrix1 + 0.01\n",
    "cos_similar_matrix1 = pd.DataFrame(cosine_similarity(dt_matrix1.values),columns=product_cat['product_id'],index=product_cat['product_id'])\n",
    "\n",
    "similarity_matrix = cos_similar_matrix.multiply(euclidean_matrix).multiply(cos_similar_matrix1)\n",
    "# content_matrix = X_train_matrix.dot(similarity_matrix)\n",
    "content_matrix = np.matrix(X_train_matrix)*np.matrix(similarity_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# apply MinMaxScaler again to obtain the trained User-Item Matrix of predicted interaction scores\n",
    "content_matrix = pd.DataFrame(content_matrix)\n",
    "std = MinMaxScaler(feature_range=(0, 1))\n",
    "std.fit(content_matrix.values)\n",
    "content_matrix = std.transform(content_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_matrix = pd.DataFrame(content_matrix,columns=sorted(X_train['product_id'].unique()),index=sorted(X_train['user_id'].unique()))\n",
    "content_df = content_matrix.stack().reset_index()\n",
    "content_df = content_df.rename(columns={'level_0':'user_id','level_1':'product_id',0:'predicted_interaction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>244951053</td>\n",
       "      <td>1001588</td>\n",
       "      <td>0.025732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244951053</td>\n",
       "      <td>1002099</td>\n",
       "      <td>0.007452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244951053</td>\n",
       "      <td>1002101</td>\n",
       "      <td>0.007452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244951053</td>\n",
       "      <td>1002102</td>\n",
       "      <td>0.007452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>244951053</td>\n",
       "      <td>1002367</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806195</th>\n",
       "      <td>512393698</td>\n",
       "      <td>52900039</td>\n",
       "      <td>0.002475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806196</th>\n",
       "      <td>512393698</td>\n",
       "      <td>52900050</td>\n",
       "      <td>0.002475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806197</th>\n",
       "      <td>512393698</td>\n",
       "      <td>52900077</td>\n",
       "      <td>0.002475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806198</th>\n",
       "      <td>512393698</td>\n",
       "      <td>52900079</td>\n",
       "      <td>0.005540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806199</th>\n",
       "      <td>512393698</td>\n",
       "      <td>53900007</td>\n",
       "      <td>0.005540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4806200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           level_0   level_1         0\n",
       "0        244951053   1001588  0.025732\n",
       "1        244951053   1002099  0.007452\n",
       "2        244951053   1002101  0.007452\n",
       "3        244951053   1002102  0.007452\n",
       "4        244951053   1002367  0.001417\n",
       "...            ...       ...       ...\n",
       "4806195  512393698  52900039  0.002475\n",
       "4806196  512393698  52900050  0.002475\n",
       "4806197  512393698  52900077  0.002475\n",
       "4806198  512393698  52900079  0.005540\n",
       "4806199  512393698  53900007  0.005540\n",
       "\n",
       "[4806200 rows x 3 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_matrix = pd.DataFrame(content_matrix,columns=sorted(X_train['product_id'].unique()),index=sorted(X_train['user_id'].unique()))\n",
    "content_df = content_matrix.stack().reset_index()\n",
    "content_df = content_df.rename(columns={'level_0':'user_id','level_1':'product_id',0:'predicted_interaction'})\n",
    "X_valid = X_valid.merge(content_df,on=['user_id','product_id'])\n",
    "\n",
    "X_valid['predicted_purchase'] = X_valid['predicted_interaction'].apply(lambda x:1 if x>=0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3433, 3433)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
