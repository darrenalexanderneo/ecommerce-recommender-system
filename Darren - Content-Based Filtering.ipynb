{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Sample 5000.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10001 entries, 0 to 10000\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   event_time     10001 non-null  object \n",
      " 1   event_type     10001 non-null  object \n",
      " 2   product_id     10001 non-null  int64  \n",
      " 3   category_id    10001 non-null  int64  \n",
      " 4   category_code  6623 non-null   object \n",
      " 5   brand          8595 non-null   object \n",
      " 6   price          10001 non-null  float64\n",
      " 7   user_id        10001 non-null  int64  \n",
      " 8   user_session   10001 non-null  object \n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 703.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Null Values\n",
    "- For brands that have null values, we're gonna replace with 'unknown' brand.\n",
    "- For category_code with null values, we're going to remove them because it would be useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          samsung\n",
       "1          samsung\n",
       "2             sony\n",
       "3            intel\n",
       "4          samsung\n",
       "           ...    \n",
       "9996           msi\n",
       "9997           msi\n",
       "9998     garanterm\n",
       "9999       samsung\n",
       "10000      samsung\n",
       "Name: brand, Length: 10001, dtype: object"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category_code'] = df['category_code'].fillna(value=\"empty\")\n",
    "df['category_code'].astype(str)\n",
    "\n",
    "df['brand'] = df['brand'].fillna(value=\"unknown\")\n",
    "df['brand'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_count = dict(df.user_id.value_counts())\n",
    "\n",
    "for row in df.iterrows():\n",
    "    \n",
    "    # Retrieving value\n",
    "    category_code_col = row[1]['category_code']\n",
    "    user_id_col = row[1]['user_id']\n",
    "    # Apply logic\n",
    "        ## We set {user-id: count_it_appears}\n",
    "        ## If count_it_appear == 1 and (category_code_col = nan), then we remove them\n",
    "        \n",
    "    count = users_count[user_id_col]\n",
    "    if count == 1 and category_code_col == 'empty':\n",
    "        df = df.drop(df[df.user_id == user_id_col].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values check:  \n",
      " event_time       0\n",
      "event_type       0\n",
      "product_id       0\n",
      "category_id      0\n",
      "category_code    0\n",
      "brand            0\n",
      "price            0\n",
      "user_id          0\n",
      "user_session     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Null Values check: \", \"\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_score'] = df['event_type'].map({'view':1, 'cart':10, 'purchase':50})\n",
    "df['user_purchase'] = df['event_type'].apply(lambda x: 1 if x == 'purchase' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bin edges must be unique: array([338.23 , 403.714, 447.37 , 447.37 , 553.342, 712.3  ]).\nYou can drop duplicate edges by setting the 'duplicates' kwarg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-459-b949c887e29b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price_category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'price_category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36mqcut\u001b[0;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0minclude_lowest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mduplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mduplicates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36m_bins_to_cuts\u001b[0;34m(x, bins, right, labels, precision, include_lowest, dtype, duplicates)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mduplicates\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             raise ValueError(\n\u001b[0;32m--> 381\u001b[0;31m                 \u001b[0;34mf\"Bin edges must be unique: {repr(bins)}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0;34mf\"You can drop duplicate edges by setting the 'duplicates' kwarg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Bin edges must be unique: array([338.23 , 403.714, 447.37 , 447.37 , 553.342, 712.3  ]).\nYou can drop duplicate edges by setting the 'duplicates' kwarg"
     ]
    }
   ],
   "source": [
    "## FIGURE THIS OUT DARREN!\n",
    "df['price_category'] = 1\n",
    "for i in df['category_code'].unique():\n",
    "    df.loc[df['category_code']==i,'price_category'] = pd.qcut(x=df['price'][df['category_code']==i],q=5, labels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "group = df.groupby(['user_id', 'product_id'])['user_score', 'user_purchase'].sum().reset_index()\n",
    "group['user_purchase'] = group['user_purchase'].apply(lambda x: 1 if x>1 else x)\n",
    "group['user_score'] = group['user_score'].apply(lambda x: 100 if x>100 else x)\n",
    "\n",
    "# apply MinMaxScaler to the user scores to obtain an interaction score with a value between 0 and 1\n",
    "# >=0.5: a very high probability that a purchase has occurred\n",
    "# <0.5: no purchase occurs below the threshold of 0.5\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "std = MinMaxScaler(feature_range=(0.025, 1))\n",
    "std.fit(group['user_score'].values.reshape(-1,1))\n",
    "group['interaction_score'] = std.transform(group['user_score'].values.reshape(-1,1))\n",
    "\n",
    "group = group.merge(df[['product_id','category_code','brand','price','price_category']].drop_duplicates('product_id'),on=['product_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = group.drop('interaction_score', axis =1)\n",
    "X = inputs\n",
    "y = group['interaction_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, \n",
    "                                                          random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matrix = pd.pivot_table(X_train,values='user_score',index='user_id',columns='product_id')\n",
    "X_train_matrix = X_train_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering by item category, price category and brand\n",
    "\n",
    "product_cat = X_train[['product_id','price_category','category_code','brand']].drop_duplicates('product_id')\n",
    "product_cat = product_cat.sort_values(by='product_id')\n",
    "\n",
    "# Reciprocal of 2 is 0.5, cos 1/2. \n",
    "price_cat_matrix = np.reciprocal(euclidean_distances(np.array(product_cat['price_category']).reshape(-1,1))+1)\n",
    "euclidean_matrix = pd.DataFrame(price_cat_matrix,columns=product_cat['product_id'],index=product_cat['product_id'])\n",
    "\n",
    "# TfidfVectorizer() converts texts to word freq counts... \n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "doc_term = tfidf_vectorizer.fit_transform(list(product_cat['category_code']))\n",
    "dt_matrix = pd.DataFrame(doc_term.toarray().round(3), index=[i for i in product_cat['product_id']], columns=tfidf_vectorizer.get_feature_names())\n",
    "cos_similar_matrix = pd.DataFrame(cosine_similarity(dt_matrix.values),columns=product_cat['product_id'],index=product_cat['product_id'])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "doc_term = tfidf_vectorizer.fit_transform(list(product_cat['brand']))\n",
    "dt_matrix1 = pd.DataFrame(doc_term.toarray().round(3), index=[i for i in product_cat['product_id']], columns=tfidf_vectorizer.get_feature_names())\n",
    "dt_matrix1 = dt_matrix1 + 0.01\n",
    "cos_similar_matrix1 = pd.DataFrame(cosine_similarity(dt_matrix1.values),columns=product_cat['product_id'],index=product_cat['product_id'])\n",
    "\n",
    "similarity_matrix = cos_similar_matrix.multiply(euclidean_matrix).multiply(cos_similar_matrix1)\n",
    "content_matrix = X_train_matrix.dot(similarity_matrix)\n",
    "\n",
    "# apply MinMaxScaler again to obtain the trained User-Item Matrix of predicted interaction scores\n",
    "std = MinMaxScaler(feature_range=(0, 1))\n",
    "std.fit(content_matrix.values)\n",
    "content_matrix = std.transform(content_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
